---
title: "Bayesian_model_comparison"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages}
library(BayesFactor) # performs Bayesian ANOVA
library(rstanarm) # bayesian regression modelling
library(bayestestR) # describes bayesian models and posterior distributions
library(bayesplot) # allows plots for posterior predictive distributions
library(loo) # Bayesian model comparison
library(arm) # computes Bayes factor for glm model
```


```{r load data}
# setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/experiment_1")
setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/experiment_1")
temp = list.files(pattern = c("magnitudedata", "*.csv")) # list all CSV files in the directory
myfiles = lapply(temp, read.csv) # read these CSV in the directory
magnitudedata <- do.call(rbind.data.frame, myfiles) # convert and combine the CSV files into dataframe

# example dataframe for stack overflow
# dput(head(magnitudedata, n = 5))
```


```{r compute model for heading variable}

magnitudedata <- magnitudedata %>%
  dplyr::filter(heading > 0)

magnitudedata$heading <- as.factor(magnitudedata$heading)

op <- options(contrasts = c("contr.helmert", "contr.poly"))

fit_aov <- stan_aov(FirstSteeringTime ~ heading, data = magnitudedata, prior = R2(location = 0.5))
fit_aov

fit_glm <- stan_glm(FirstSteeringTime ~ heading, family = Gamma(link = "identity"), data = magnitudedata)
fit_glm

```

The *stan_aov* function performs Bayesian analysis of variance. Using this function allows you input priors based on the R2 values (the proportion of variance explained of your outcome variable by your predictors). Hence if I can compute the R2 from my ANOVA model from experiment 1, I can input this as a prior for analysis of experiment 2.


The R2 values represents how much variance in the dependent variable can be explained by the independent variable. The R2 of the *stan_aov* matches what would be achieved using a standard linear regression.

The *stan_glm* function allows me to compute a generalised linear model with a gamma dsitribution. A gamma distribution is a better fit for my data (rather than a gaussian) due to it being continous data, having a right skew and not encompassing zero (it is not possible to have negative RTs))

I have left the priors as a default meaning they are weakly informative
nhttps://mc-stan.org/rstanarm/articles/continuous.html#gamma-regression-example

```{r posterior predictive distribution for the stan_aov model}

# observed data responses
y <- magnitudedata$FirstSteeringTime

# sample draws from the posterior distribution
yrep_aov <- posterior_predict(fit_aov, draws = 50)

color_scheme_set("brightblue")
ppc_dens_overlay(y, yrep_aov[1:50, ])

```

A *posterior distribution* explains an unknown random parameter and provides the 95% mo credible values for that parameter.

A *posterior predictive distribution* refers to a distribution of future predicted data based upon the data already seen. 

If the model is a good fit, we should be able to use it to generate data that looks like data we observed in the experiment. 

When we use the *stan_aov* model and implement a density plot, it vastly under predicts the the number of responses at around 0.5 in the observed y vector. The model thus predicts fewer 0.5 RTs than was actually observed.

This model also proposes the peak of the responses (i.e. the highest density of responses) as slower than the observed peak responses. 

```{r posterior predictive distribution for the stan_glm model}

# observed data responses
y <- magnitudedata$FirstSteeringTime

# sample draws from the posterior distribution
yrep_glm <- posterior_predict(fit_glm, draws = 500)

color_scheme_set("brightblue")
ppc_dens_overlay(y, yrep_glm[1:50, ])

```

The *stan_glm* model also underestimates the number of responses at around 0.5. However, it provides a better description of the response peaks. Hence this model appears to be a better description of the data than the *stan_aov* model.

It appears that modelling the data with a gamma distribution generates a better fit to the data. 

```{r model comparison using the loo package}

loo_aov <- loo(fit_aov)

loo_glm <- loo(fit_glm)

print(loo_compare(loo_aov, loo_glm), digits = 3)

```

The *loo_compare* function compares my two Bayesian model fits using the "leave one out" cross validaion method. This method essentially investigates the differences in predictive errors and standard errors for each model. This is encapsulated by the *elpd_diff* (predictive errors) and *se_diff* (standard errors) variables.

Columns within the matrix are computed by generating pairwise comparisons between each model and the model with highest ELPD (i.e. highest predictive accuracy). Because of this, the first row will always be zeros because this is the preferred model compared against itself. 

When the difference (*elpd_diff*) is positive, the expected predictive accuracy is higher for the second model. When it is negative, this favours the first model. Hence because my *elpd_diff* shows a large negative, model2 (fit_glm) is the preferred model. 

```{r testing model parameters with Bayes factors}

My_first_BF <- bayesfactor_parameters(fit_glm, null = c(-.02,.02))
My_first_BF
plot(My_first_BF)

```

The previous was taken from the example given here: https://easystats.github.io/bayestestR/articles/bayes_factors.html#testing-models-parameters-with-bayes-factors

The Bayes factor proposes that the data is 2.42 * 10^4 times more likely under the alternative model hypothesis than under the null model hypothesis.

In essence by the *stan_aov* and the *stan_glm* models both indicate strong evidence for the alternative models. However, the GLM with gamma distribution models the response better as my data is not normally distributed. This is highlighted in the *loo* model comparison. 

```{r plotting model the regression line and posterior draws from the GLM model}

draws <- as.data.frame(fit_glm)
colnames(draws)[1:2] <- c("a", "b")


ggplot(magnitudedata, aes(x = heading, y = FirstSteeringTime)) + 
  geom_point(size = 1, position = position_jitter(height = 0.05, width = 0.1), alpha = 0.3) + 
  geom_abline(data = draws, aes(intercept = a, slope = b), 
              color = "skyblue", size = 0.2, alpha = 0.25) + 
  geom_abline(intercept = coef(fit_glm)[1], slope = coef(fit_glm)[2], 
                   color = "skyblue4", size = 1) 
  
```

The previous was taken from the example given here:

http://mc-stan.org/rstanarm/articles/continuous.html#gamma-regression-example

This plots the regression line for the selected contrast that was computed from the Bayesian model. The uncertainty is visualised via draws from the posterior distribution at each heading angle.

**TO DO**

Investigate the point below by plotting different contrasts (perhaps facet_wrap per contrast?)

- Need to be careful here and plot only the points that relate to the contrast. I.e. if I have selected the 1.0 vs 1.5 heading contrast, I should only plot 1.0 and 1.5 on the graph
