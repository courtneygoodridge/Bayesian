---
title: "bayesain_gganimate"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This R markdown file will detail how to visualise the accumulation of evidence that occurs during Bayesian analysis. Frequentist analyses assume that the null hypothesis model is true, and then compute the probability of the simulated data under the null being as extreme as the obtained data. If the probability is low, the null is rejected and the alternative hypothesis is accepted.

Within the Bayesian framework, a null and alternative model hypothesis are stated and represented as a prior distribution. The null model hypothesis is represented as an infintesmitely small spike on the null value of no effect. The alternative model hypothesis can be represented by a distribution on where the researcher expects the  the effect to be (driven by prior knowledge or expeirmentation). Each model has a mdoel-index parameter. Before data is obtained, credibility is equal between these parameters. As data is obtained, the model-indexes are updated via Bayes rule to reallocate credibility for each of the model indexes.

The key difference between them is that the frequentist approach identifies the probability of data, given that the theory is true (p(data | theory)). Theoretically this does not make too much sence as the null hypothesis is rarely true and thus deviation from it is always quite likely given enough data.

Alternatively, Bayesian frameworks identify the probability of theory, given the obtained data (p(theory | data)). This is actually what researchers want the answer to and Bayesian analysis gives them this. 

## Load packages

```{r}
# rm(list = ls())
library(rstanarm)
library(ggplot2)
library(gganimate)
library(dplyr)
library(tidyr)
library(transformr)
library(gifski)
library(bayestestR)
library(see)
library(insight)
library(devtools)
install_github("easystats/estimate")
library(magick)
```

## Loading my own data

```{r}
setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/experiment_1")
temp = list.files(pattern = c("magnitudedata", "*.csv"))
myfiles = lapply(temp, read.csv)
magnitudedata <- do.call(rbind.data.frame, myfiles)

magnitudedata$heading <- as.factor(magnitudedata$heading)
```

## Simulating data and fitting Bayesian models 

```{r}
true_effect <- 0.5
prior_width <- 0.333
max_n <- 10


data <- bayestestR::simulate_correlation(n=max_n, r=true_effect)
vizmatrix <- estimate::visualisation_matrix(data["V2"])

# Initialize empty dataframes
priors <- data.frame()
posteriors <- data.frame()
params <- data.frame()
prediction <- data.frame()
correlation_data <- data.frame()
for(i in 5:nrow(data)){
  print(i)

  # Get data
  current_data <- data[1:i,]
  current_data$Evidence <- i
  correlation_data <- rbind(correlation_data, current_data)

  # Model and make predictions
  model <- rstanarm::stan_glm(V1 ~ V2,
                              prior = normal(0, prior_width),
                              data=current_data,
                              refresh = 0,
                              iter=10000,
                              chains=4,
                              warmup=4000)


  current_prediction <- estimate::estimate_link(model, length=50, data=vizmatrix, keep_draws=FALSE, draws=10)
  current_prediction$Evidence <- i
  prediction <- rbind(prediction, current_prediction)

  # Parameters
  posterior <- insight::get_parameters(model)$V2
  param <- bayestestR::describe_posterior(model, test=c("pd", "ROPE", "p_MAP"), rope_ci = 1)[2,]
  param$BF_null <- bayestestR::bayesfactor_parameters(model, verbose = FALSE)[2, "BF"]
  param$BF_ROPE <- bayesfactor_parameters(model, null = rope_range(model))[2, "BF"]

  param$Max <- bayestestR::density_at(posterior, median(posterior), method="KernSmooth")
  param$Evidence <- i
  params <- rbind(params, param)

  # Prior and posterior
  posterior <- bayestestR::estimate_density(posterior, method="KernSmooth")
  posterior$Evidence <- i
  posteriors <- rbind(posteriors, posterior)

  prior <- bayestestR::estimate_density(bayestestR::distribution_normal(1000, 0, prior_width), method="KernSmooth")
  prior$Evidence <- i
  priors <- rbind(priors, prior)
}


```

The code above first simulates correlation data. For each row in the dataframe, it computes a Bayesian model. Using the *estimate_link* function, predicitions are computed from the inputted model. These include 95% CIs and HDIs. These can then be used for plotting alongside the median generated from the posterior distribution. 

The parameters for the model are then computed. This includes the posterior distribution and the prior dsitribution. The posterior distribution is then described from the model under 3 tests:

- *pd (probability of direction)*. This varies from 50% to 100% and indicates the probability that a parameter described by the posterior distribution is positive or negative. Mathematically it is defined as the percentage of the posterior distribution that is the same sign as the median of the distribution. 

- *ROPE (region of practical equivalence)*. This  computes the percentage if the posterior distribution that is within a region that is practically equivalent to the null value. 

- *p_MAP (probability of maximum a posteriori)*. This is the Bayesian equivalent of frequentist p value. Relates to the odds that a parameter, as described by the posterior distribution, has against the null hypothesis. Mathematically, it can be described as the density value at 0 divided by the maximum a posteriori (MAP).

- *BF_NULL (Bayes factor against the null hypothesis)*. This represents evidence against the null hypothesis. This parameters is computed against a point null.

- *BF_ROPE (Bayes factor against the rope'd null hypothesis)*. Represents evidence against the null hypothesis and a region of practicaly equivalence to the null value. 

## Plotting figures

```{r}
p_correlation <- correlation_data %>%
  ggplot(aes(y=V1, x=V2)) +
  geom_point(size=3) +
  geom_ribbon(data=prediction, aes(ymin=CI_low, y=Median, ymax=CI_high, fill=Evidence), alpha=0.3) +
  geom_line(data=prediction, aes(y=Median, color=Evidence), size=1) +
  see::theme_modern() +
  xlab("Variable 1") +
  ylab("Variable 2") +
  scale_colour_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  scale_fill_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  gganimate::transition_time(Evidence) +
  labs(title = "Evidence (Sample Size): {frame_time}")


p_posterior <- posteriors %>%
  ggplot(aes(x=x, y=y)) +
  geom_area(data=priors, fill="#2196F3", alpha=1) +
  geom_segment(x = 0 , y = 0, xend = 0, yend = max(priors$y), size=0.5, color="#3F51B5", linetype = "dashed") +
  geom_segment(data=params, aes(x = Median , y = 0, xend = Median, yend = Max, color=Evidence), size=0.5, linetype = "dashed") +
  geom_line(aes(color=Evidence), size=1.5) +
  geom_vline(xintercept=true_effect, color="#E91E63", size=1) +
  scale_colour_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  annotate("segment", x = 0.05, xend = true_effect, y = 1.25, yend = 1.25, colour = "#E91E63", size=1, arrow=arrow(length = unit(0.10, "inches"), type="closed")) +
  annotate("text", x = 0, y = 1.25, hjust = 1, colour = "#E91E63", label="True effect") +
  annotate("segment", x = -0.7, xend = -prior_width, y = 0.75, yend = 0.75, colour = "#2196F3", size=1, arrow=arrow(length = unit(0.10, "inches"), type="closed")) +
  annotate("text", x = -0.75, y = 0.75, hjust = 1, colour = "#2196F3", label="Prior") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 7)) +
  scale_y_continuous(expand = c(0, 0)) +
  see::theme_modern() +
  xlab("Effect") +
  ylab("Probability") +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  coord_cartesian(xlim=c(-1, 1)) +
  gganimate::transition_time(Evidence)


p_significance <- params %>%
  select(Evidence, `p (direction)`=pd, `p (0)`=p_MAP, `p (ROPE)`=ROPE_Percentage, `BF (0)`=BF_null, `BF (ROPE)`= BF_ROPE) %>%
  tidyr::pivot_longer(cols=-Evidence, names_to = "Index", values_to = "Value") %>%
  mutate(Index = forcats::fct_relevel(Index, "p (direction)", "p (0)", "p (ROPE)", "BF (ROPE)", "BF (0)")) %>%
  ggplot(aes(x=Evidence, y=Value, color=Index, group=1)) +
  geom_line(size=2) +
  scale_color_manual(values = c("p (direction)"="#9C27B0", "p (0)"="#f44336", "p (ROPE)"="#FFC107", "BF (0)"="#4CAF50", "BF (ROPE)"="#CDDC39"), guide=FALSE) +
  facet_wrap(~Index, nrow=5, scales = "free") +
  ylab("") +
  xlab("Evidence (Sample Size)") +
  see::theme_modern() +
  gganimate::transition_reveal(Evidence)


```

## Saving figures is one main figure

```{r}
p1 <- magick::image_read(animate(p_correlation, duration=nrow(example)/4, fps=20))
p2 <- magick::image_read(animate(p_posterior, duration=nrow(example)/4, fps=20))
p3 <- magick::image_read(animate(p_significance, duration=nrow(example)/4, fps=20))

final <- magick::image_append(c(p1[1], p2[1], p3[1]))
for(i in 2:length(p2)){
  combined <- magick::image_append(c(p1[i], p2[i], p3[i]))
  final <- c(final, combined)
}

# Save final
gganimate::anim_save("evidence_accumulation.gif", final)
```

Now that I have reproduced the example, I will compute the same with my own data. 

## Selecting example participant and fitting model for each trial

```{r}

prior_width <- 0.1

example <- magnitudedata %>%
  dplyr::select(heading, FirstSteeringTime, pNum) %>%
  dplyr::filter(pNum < 4)

vizmatrix <- estimate::visualisation_matrix(magnitudedata["heading"], length = 5)

# Initialize empty dataframes
priors <- data.frame()
posteriors <- data.frame()
params <- data.frame()
prediction <- data.frame()
correlation_data <- data.frame()
for(i in 10:nrow(example)){
  print(i)

  # Get data
  current_data <- example[1:i,]
  current_data$Evidence <- i
  correlation_data <- rbind(correlation_data, current_data)

  # Model and make predictions
  model <- rstanarm::stan_glm(FirstSteeringTime ~ heading,
                              prior = cauchy(0, prior_width),
                              family = Gamma(link = "identity"),
                              data=current_data)


  current_prediction <- estimate::estimate_link(model, length=50, data=vizmatrix, keep_draws=FALSE, draws=10)
  current_prediction$Evidence <- i
  prediction <- rbind(prediction, current_prediction)

  # Parameters
  posterior <- insight::get_parameters(model)$heading
  param <- bayestestR::describe_posterior(model, test=c("pd", "ROPE", "p_MAP"), rope_ci = 1)[2,]
  param$BF_null <- bayestestR::bayesfactor_parameters(model, verbose = FALSE)[2, "BF"]
  param$BF_ROPE <- bayesfactor_parameters(model, null = rope_range(model))[2, "BF"]

  param$Max <- bayestestR::density_at(posterior, median(posterior), method="KernSmooth")
  param$Evidence <- i
  params <- rbind(params, param)

  # Prior and posterior
  posterior <- bayestestR::estimate_density(posterior, method="KernSmooth")
  posterior$Evidence <- i
  posteriors <- rbind(posteriors, posterior)

  prior <- bayestestR::estimate_density(bayestestR::distribution_normal(1000, 0, prior_width), method="KernSmooth")
  prior$Evidence <- i
  priors <- rbind(priors, prior)
}
```

## Plotting figures

```{r}

p_correlation <- correlation_data %>%
  ggplot(aes(y = FirstSteeringTime, x = heading)) +
  geom_point(size=3) +
  geom_ribbon(data=prediction, aes(ymin=CI_low, y=Median, ymax=CI_high, fill=Evidence), alpha=0.3) +
  geom_line(data = prediction, aes(y = Median, color = Evidence), size = 1) +
  see::theme_modern() +
  xlab("Variable 1") +
  ylab("Variable 2") +
  scale_colour_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  scale_fill_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  gganimate::transition_time(Evidence) +
  labs(title = "Evidence (Sample Size): {frame_time}")


p_posterior <- posteriors %>%
  ggplot(aes(x=x, y=y)) +
  geom_segment(x = 0 , y = 0, xend = 0, yend = max(priors$y), size=0.5, color="#3F51B5", linetype = "dashed") +
  geom_segment(data=params, aes(x = Median , y = 0, xend = Median, yend = Max, color=Evidence), size=0.5, linetype = "dashed") +
  geom_line(aes(color=Evidence), size=1.5) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 7)) +
  scale_y_continuous(expand = c(0, 0)) +
  see::theme_modern() +
  xlab("Effect") +
  ylab("Probability") +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  coord_cartesian(xlim=c(-0.5, 0.5)) +
  gganimate::transition_time(Evidence)

p_significance <- params %>%
  mutate(BF = 1 / abs(BF_null), BF_ROPED = 1 / abs(BF_ROPE)) %>%
  select(Evidence, `p (direction)`=pd, `p (0)`=p_MAP, `p (ROPE)`=ROPE_Percentage, `BF (0)`=BF, `BF (ROPE)`= BF_ROPED) %>%
  tidyr::pivot_longer(cols=-Evidence, names_to = "Index", values_to = "Value") %>%
  mutate(Index = forcats::fct_relevel(Index, "p (direction)", "p (0)", "p (ROPE)", "BF (0)", "BF (ROPE)")) %>%
  ggplot(aes(x=Evidence, y=Value, color=Index, group=1)) +
  geom_line(size=2) +
  scale_color_manual(values = c("p (direction)"="#9C27B0", "p (0)"="#f44336", "p (ROPE)"="#FFC107", "BF (0)"="#4CAF50", "BF (ROPE)"="#CDDC39"), guide=FALSE) +
  facet_wrap(~Index, nrow=5, scales = "free") +
  ylab("") +
  xlab("Evidence (Number of trials)") +
  see::theme_modern() +
  gganimate::transition_reveal(Evidence)

setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/Bayesian")

anim <- animate(p_significance)
anim_save("significance.gif", anim)

```





**p_significance**

*p(ROPE)*

This represents the percentage of the posterior distribution that is in a region of practical equivalance to the null. Just before 200 trials, it is driven down to 0%, thus 0% of the most credible values of the effect are practically equivalent to the null. 

*BF(0) and BF(ROPE)*

Here I make a slight alteration to the code. I take the inverse of the Bayes factor and the Bayes factor ROPE as specified here (https://easystats.github.io/report/articles/interpret_metrics.html#bayes-factor-bf). This means that the interpretation of these Bayes factors are now the amount of evidence in favour of the null model hypothesis, given the data. As data is collected, evidence for the null model gets driven down to zero. The alternative hypothesis is thus more likely given the data. 

## Saving figures

```{r}
p1 <- magick::image_read(animate(p_correlation, duration=nrow(example)/4, fps=20))
p2 <- magick::image_read(animate(p_posterior, duration=nrow(example)/4, fps=20))
p3 <- magick::image_read(animate(p_significance, duration=nrow(example)/4, fps=20))

final <- magick::image_append(c(p1[1], p2[1], p3[1]))
for(i in 2:length(p2)){
  combined <- magick::image_append(c(p1[i], p2[i], p3[i]))
  final <- c(final, combined)
}

# Save final
gganimate::anim_save("evidence_accumulation.gif", final)

```