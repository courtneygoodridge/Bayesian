---
title: "bayesain_gganimate"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Aim of this markdown

This R markdown file will detail how to visualise the accumulation of evidence that occurs during Bayesian analysis. Frequentist analyses assume that the null hypothesis model is true, and then compute the probability of the simulated data under the null being as extreme as the obtained data. If the probability is low, the null is rejected and the alternative hypothesis is accepted.

Within the Bayesian framework, a null and alternative model hypothesis are stated and represented as a prior distribution. The null model hypothesis is represented as an infintesmitely small spike on the null value of no effect. The alternative model hypothesis can be represented by a distribution on where the researcher expects the  the effect to be (driven by prior knowledge or expeirmentation). Each model has a mdoel-index parameter. Before data is obtained, credibility is equal between these parameters. As data is obtained, the model-indexes are updated via Bayes rule to reallocate credibility for each of the model indexes.

The key difference between them is that the frequentist approach identifies the probability of data, given that the theory is true (p(data | theory)). Theoretically this does not make too much sence as the null hypothesis is rarely true and thus deviation from it is always quite likely given enough data.

Alternatively, Bayesian frameworks identify the probability of theory, given the obtained data (p(theory | data)). This is actually what researchers want the answer to and Bayesian analysis gives them this. 

## Load packages

```{r}
# rm(list = ls())
library(rstanarm)
library(ggplot2)
library(gganimate)
library(dplyr)
library(tidyr)
library(transformr)
library(gifski)
library(bayestestR)
library(see)
library(insight)
library(devtools)
install_github("easystats/estimate")
library(magick)
library(logspline)
library(psych)
```

## Loading my own data

```{r}
# setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/experiment_1")
setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/experiment_1")
temp = list.files(pattern = c("magnitudedata", "*.csv"))
myfiles = lapply(temp, read.csv)
magnitudedata <- do.call(rbind.data.frame, myfiles)

magnitudedata$heading <- as.factor(magnitudedata$heading)
```

## Simulating ANOVA data with 0 effect

```{r}
df <- sim.anova(es1 = 0, n1 = 4, factors = TRUE, std = TRUE) # 1 IV, 3 levels

IV4 <- c(0, 0, 0, 2, 2, 2, 0, 0, 0.5, 0.5, 0, 0, 0, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 1, 1, 0.5, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2)

df <- data.frame(IV4, df)
```

The code chunk above simulates an ANOVA with one IV with 4 levels that has no effect. I will use this dataframe to show that with the addition of data, the posterior distribution will centre on the null value.

## Fitting Bayesian model to ANOVA data with zero effect

```{r}
prior_width <- 0.333
# Initialize empty dataframes
priors <- data.frame()
posteriors <- data.frame()
params <- data.frame()
prediction <- data.frame()
correlation_data <- data.frame()
for(i in 1:nrow(df)){
  print(i)

  # Get data
  current_data <- df[1:i,]
  current_data$Evidence <- i
  correlation_data <- rbind(correlation_data, current_data)

  # Model and make predictions
  model <- rstanarm::stan_glm(DV ~ IV4,
                              prior = normal(0, prior_width),
                              family = gaussian(),
                              data=current_data,
                              adapt_delta = 0.95)


  current_prediction <- estimate::estimate_link(model, length=50, data=vizmatrix, keep_draws=FALSE, draws=10)
  current_prediction$Evidence <- i
  prediction <- rbind(prediction, current_prediction)

  # Parameters
  posterior <- insight::get_parameters(model)$IV4
  param <- bayestestR::describe_posterior(model, test=c("pd", "ROPE", "p_MAP"), rope_ci = 1)[2,]
  param$BF_null <- bayestestR::bayesfactor_parameters(model, verbose = FALSE)[2, "BF"]
  param$BF_ROPE <- bayesfactor_parameters(model, null = rope_range(model))[2, "BF"]

  param$Max <- bayestestR::density_at(posterior, median(posterior), method="KernSmooth")
  param$Evidence <- i
  params <- rbind(params, param)

  # Prior and posterior
  posterior <- bayestestR::estimate_density(posterior, method="KernSmooth")
  posterior$Evidence <- i
  posteriors <- rbind(posteriors, posterior)

  prior <- bayestestR::estimate_density(bayestestR::distribution_normal(1000, 0, prior_width), method="KernSmooth")
  prior$Evidence <- i
  priors <- rbind(priors, prior)
}
```

The above code chunk fits a Bayesian model with gaussian family and identity link function. 

## Simulating data and fitting Bayesian models froM GitHub example

```{r}
true_effect <- 0.5
prior_width <- 0.333
max_n <- 10


data <- bayestestR::simulate_correlation(n=max_n, r=true_effect)
vizmatrix <- estimate::visualisation_matrix(data["V2"])

# Initialize empty dataframes
priors <- data.frame()
posteriors <- data.frame()
params <- data.frame()
prediction <- data.frame()
correlation_data <- data.frame()
for(i in 5:nrow(data)){
  print(i)

  # Get data
  current_data <- data[1:i,]
  current_data$Evidence <- i
  correlation_data <- rbind(correlation_data, current_data)

  # Model and make predictions
  model <- rstanarm::stan_glm(V1 ~ V2,
                              prior = normal(0, prior_width),
                              data=current_data,
                              refresh = 0,
                              iter=10000,
                              chains=4,
                              warmup=4000)


  current_prediction <- estimate::estimate_link(model, length=50, data=vizmatrix, keep_draws=FALSE, draws=10)
  current_prediction$Evidence <- i
  prediction <- rbind(prediction, current_prediction)

  # Parameters
  posterior <- insight::get_parameters(model)$V2
  param <- bayestestR::describe_posterior(model, test=c("pd", "ROPE", "p_MAP"), rope_ci = 1)[2,]
  param$BF_null <- bayestestR::bayesfactor_parameters(model, verbose = FALSE)[2, "BF"]
  param$BF_ROPE <- bayesfactor_parameters(model, null = rope_range(model))[2, "BF"]

  param$Max <- bayestestR::density_at(posterior, median(posterior), method="KernSmooth")
  param$Evidence <- i
  params <- rbind(params, param)

  # Prior and posterior
  posterior <- bayestestR::estimate_density(posterior, method="KernSmooth")
  posterior$Evidence <- i
  posteriors <- rbind(posteriors, posterior)

  prior <- bayestestR::estimate_density(bayestestR::distribution_normal(1000, 0, prior_width), method="KernSmooth")
  prior$Evidence <- i
  priors <- rbind(priors, prior)
}
```

The code above first simulates correlation data. For each row in the dataframe, it computes a Bayesian model. Using the *estimate_link* function, predicitions are computed from the inputted model. These include 95% CIs and HDIs. These can then be used for plotting alongside the median generated from the posterior distribution. 

The parameters for the model are then computed. This includes the posterior distribution and the prior dsitribution. The posterior distribution is then described from the model under 3 tests:

- *pd (probability of direction)*. This varies from 50% to 100% and indicates the probability that a parameter described by the posterior distribution is positive or negative. Mathematically it is defined as the percentage of the posterior distribution that is the same sign as the median of the distribution. 

- *ROPE (region of practical equivalence)*. This  computes the percentage if the posterior distribution that is within a region that is practically equivalent to the null value. 

- *p_MAP (probability of maximum a posteriori)*. This is the Bayesian equivalent of frequentist p value. Relates to the odds that a parameter, as described by the posterior distribution, has against the null hypothesis. Mathematically, it can be described as the density value at 0 divided by the maximum a posteriori (MAP).

- *BF_NULL (Bayes factor against the null hypothesis)*. This represents evidence against the null hypothesis. This parameters is computed against a point null.

- *BF_ROPE (Bayes factor against the rope'd null hypothesis)*. Represents evidence against the null hypothesis and a region of practicaly equivalence to the null value. 

## Plotting figures

```{r}
p_correlation <- correlation_data %>%
  ggplot(aes(y=V1, x=V2)) +
  geom_point(size=3) +
  geom_ribbon(data=prediction, aes(ymin=CI_low, y=Median, ymax=CI_high, fill=Evidence), alpha=0.3) +
  geom_line(data=prediction, aes(y=Median, color=Evidence), size=1) +
  see::theme_modern() +
  xlab("Variable 1") +
  ylab("Variable 2") +
  scale_colour_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  scale_fill_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  gganimate::transition_time(Evidence) +
  labs(title = "Evidence (Sample Size): {frame_time}")


p_posterior <- posteriors %>%
  ggplot(aes(x=x, y=y)) +
  geom_area(data=priors, fill="#2196F3", alpha=1) +
  geom_segment(x = 0 , y = 0, xend = 0, yend = max(priors$y), size=0.5, color="#3F51B5", linetype = "dashed") +
  geom_segment(data=params, aes(x = Median , y = 0, xend = Median, yend = Max, color=Evidence), size=0.5, linetype = "dashed") +
  geom_line(aes(color=Evidence), size=1.5) +
  geom_vline(xintercept=true_effect, color="#E91E63", size=1) +
  scale_colour_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  annotate("segment", x = 0.05, xend = true_effect, y = 1.25, yend = 1.25, colour = "#E91E63", size=1, arrow=arrow(length = unit(0.10, "inches"), type="closed")) +
  annotate("text", x = 0, y = 1.25, hjust = 1, colour = "#E91E63", label="True effect") +
  annotate("segment", x = -0.7, xend = -prior_width, y = 0.75, yend = 0.75, colour = "#2196F3", size=1, arrow=arrow(length = unit(0.10, "inches"), type="closed")) +
  annotate("text", x = -0.75, y = 0.75, hjust = 1, colour = "#2196F3", label="Prior") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 7)) +
  scale_y_continuous(expand = c(0, 0)) +
  see::theme_modern() +
  xlab("Effect") +
  ylab("Probability") +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  coord_cartesian(xlim=c(-1, 1)) +
  gganimate::transition_time(Evidence)


p_significance <- params %>%
  select(Evidence, `p (direction)`=pd, `p (0)`=p_MAP, `p (ROPE)`=ROPE_Percentage, `BF (0)`=BF_null, `BF (ROPE)`= BF_ROPE) %>%
  tidyr::pivot_longer(cols=-Evidence, names_to = "Index", values_to = "Value") %>%
  mutate(Index = forcats::fct_relevel(Index, "p (direction)", "p (0)", "p (ROPE)", "BF (ROPE)", "BF (0)")) %>%
  ggplot(aes(x=Evidence, y=Value, color=Index, group=1)) +
  geom_line(size=2) +
  scale_color_manual(values = c("p (direction)"="#9C27B0", "p (0)"="#f44336", "p (ROPE)"="#FFC107", "BF (0)"="#4CAF50", "BF (ROPE)"="#CDDC39"), guide=FALSE) +
  facet_wrap(~Index, nrow=5, scales = "free") +
  ylab("") +
  xlab("Evidence (Sample Size)") +
  see::theme_modern() +
  gganimate::transition_reveal(Evidence)


```

## Saving figures is one main figure

```{r}
p1 <- magick::image_read(animate(p_correlation, duration=nrow(example)/4, fps=20))
p2 <- magick::image_read(animate(p_posterior, duration=nrow(example)/4, fps=20))
p3 <- magick::image_read(animate(p_significance, duration=nrow(example)/4, fps=20))

final <- magick::image_append(c(p1[1], p2[1], p3[1]))
for(i in 2:length(p2)){
  combined <- magick::image_append(c(p1[i], p2[i], p3[i]))
  final <- c(final, combined)
}

# Save final
gganimate::anim_save("evidence_accumulation.gif", final)
```

Now that I have reproduced the example, I will compute the same with my own data. 

## Fitting model for each trial (within each participant)

```{r}
prior_width <- 0.02
#namevector <- c("Evidence")

example <- magnitudedata %>%
  dplyr::select(heading, FirstSteeringTime, pNum) %>%
  dplyr::filter(pNum == 11)

vizmatrix <- estimate::visualisation_matrix(magnitudedata["heading"], length = 5)

# Initialize empty dataframes
current_data <- data.frame()
priors <- data.frame()
posteriors <- data.frame()
params <- data.frame()
prediction <- data.frame()
correlation_data <- data.frame()

for(i in 11:nrow(example)){
  print(i)

  # Get data
  current_data <- example[1:i,]
  current_data$Evidence <- i
  correlation_data <- rbind(correlation_data, current_data)

  # Model and make predictions
  model <- rstanarm::stan_glm(FirstSteeringTime ~ heading,
                              prior = cauchy(0, prior_width),
                              family = Gamma(link = "identity"),
                              data=current_data)


  current_prediction <- estimate::estimate_link(model, length=50, data=vizmatrix, keep_draws=FALSE, draws=10)
  current_prediction$Evidence <- i
  prediction <- rbind(prediction, current_prediction)

  # Parameters
  posterior <- insight::get_parameters(model)$heading
  param <- bayestestR::describe_posterior(model, test=c("pd", "ROPE", "p_MAP"), rope_ci = 1)[2,]
  param$BF_null <- bayestestR::bayesfactor_parameters(model, verbose = FALSE)[2, "BF"]
  param$BF_ROPE <- bayesfactor_parameters(model, null = rope_range(model))[2, "BF"]

  param$Max <- bayestestR::density_at(posterior, median(posterior), method="KernSmooth")
  param$Evidence <- i
  params <- rbind(params, param)

  # Prior and posterior
  posterior <- bayestestR::estimate_density(posterior, method="KernSmooth")
  posterior$Evidence <- i
  posteriors <- rbind(posteriors, posterior)

  prior <- bayestestR::estimate_density(bayestestR::distribution_cauchy(1000, 0, prior_width), method="KernSmooth")
  prior$Evidence <- i
  priors <- rbind(priors, prior)
}
```

The code in the chunk above runs a Bayesian model for each trial for a given participant. I can choose to select multiple participants and compute model for each trial also. Prior distribution I use here is the cauchy with a scale value of 0.02. As specified here (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations) you want an informative prior that rule out unreasonable values but not to rule out higher values tat could be true given the data. A cauchy dsitrbiution has fat tails which assigns probability to larger values. Because these values are less likely overall, a prior distribution like this favours the null model hypothesis and thus is considered more conservative. 

## Fitting model for each participant

```{r}

prior_width <- 0.2
namevector <- c("Evidence")

vizmatrix <- estimate::visualisation_matrix(magnitudedata["heading"], length = 5)

# Initialize empty dataframes
current_data <- data.frame()
priors <- data.frame()
posteriors <- data.frame()
params <- data.frame()
prediction <- data.frame()
correlation_data <- data.frame()
for(i in c(1:19)){
  print(i)

  # Get data
  tmp_data <- magnitudedata[magnitudedata$pNum == i,]
  tmp_data[ , namevector] <- NA
  current_data <- rbind(current_data, tmp_data)
  current_data$Evidence <- i
  correlation_data <- rbind(correlation_data, current_data)

  # Model and make predictions
  model <- rstanarm::stan_glm(FirstSteeringTime ~ heading,
                              prior = cauchy(0, prior_width),
                              family = Gamma(link = "identity"),
                              adapt_delta = 0.95,
                              data=current_data)


  current_prediction <- estimate::estimate_link(model, length=50, data=vizmatrix, keep_draws=FALSE, draws=10)
  current_prediction$Evidence <- i
  prediction <- rbind(prediction, current_prediction)

  # Parameters
  posterior <- insight::get_parameters(model)$heading
  param <- bayestestR::describe_posterior(model, test=c("pd", "ROPE", "p_MAP"), rope_ci = 1)[2,]
  param$BF_null <- bayestestR::bayesfactor_parameters(model, verbose = FALSE)[2, "BF"]
  param$BF_ROPE <- bayesfactor_parameters(model, null = rope_range(model))[2, "BF"]

  param$Max <- bayestestR::density_at(posterior, median(posterior), method="KernSmooth")
  param$Evidence <- i
  params <- rbind(params, param)

  # Prior and posterior
  posterior <- bayestestR::estimate_density(posterior, method="KernSmooth")
  posterior$Evidence <- i
  posteriors <- rbind(posteriors, posterior)

  prior <- bayestestR::estimate_density(bayestestR::distribution_cauchy(1000, 0, prior_width), method="KernSmooth")
  prior$Evidence <- i
  priors <- rbind(priors, prior)
}
```

In the above code chunk, I compute a Bayesian model for each participant ("evidence refers to participants"). This makes more sense as the Bayesian posterior chnages with every new participant. For this example, I will run the model with a normal distribution as the prior. According to https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations, a normal distribution centred at 0 with a scale of 1 is generic weakly informative prior.

It is important to know that the distribution refers to where and what the coefficient might be, rather than modelling the response variable itself. The latter is computed within the Bayesian GLM model via assigning a specific family and link function. 

## Plotting figures

```{r}

p_correlation <- correlation_data %>%
  ggplot(aes(y = FirstSteeringTime, x = heading)) +
  geom_jitter(size = 3, width = 0.25) +
  geom_ribbon(data=prediction, aes(ymin=CI_low, y=Median, ymax=CI_high, fill=Evidence), alpha=0.3) +
  geom_line(data = prediction, aes(y = Median, color = Evidence), size = 1) +
  see::theme_modern() +
  xlab("Heading") +
  ylab("Reaction time (RT)") +
  scale_colour_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  scale_fill_gradient(low = "#FFC107", high = "#E91E63", guide = FALSE) +
  gganimate::transition_time(Evidence) +
  labs(title = "Evidence (Sample Size): {frame_time}")


p_posterior <- posteriors %>%
  ggplot(aes(x=x, y=y)) +
  geom_area(data = priors, fill="#2196F3", alpha=1) +
  geom_segment(x = 0 , y = 0, xend = 0, yend = max(priors$y), size=0.5, color="#3F51B5", linetype = "dashed") +
  geom_segment(data=params, aes(x = Median , y = 0, xend = Median, yend = Max, color=Evidence), size=0.5, linetype = "dashed") +
  geom_line(aes(color=Evidence), size=1.5) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 7)) +
  scale_y_continuous(expand = c(0, 0)) +
  see::theme_modern() +
  xlab("Effect") +
  ylab("Probability") +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  coord_cartesian(xlim=c(-0.5, 0.5)) +
  gganimate::transition_time(Evidence) +
  labs(title = "Evidence (Sample size): {frame_time}")


p_significance <- params %>%
  mutate(BF = 1 / abs(BF_null), BF_ROPED = 1 / abs(BF_ROPE)) %>%
  select(Evidence, `p (direction)`=pd, `p (0)`=p_MAP, `p (ROPE)`=ROPE_Percentage, `BF (0)`=BF, `BF (ROPE)`= BF_ROPED) %>%
  tidyr::pivot_longer(cols=-Evidence, names_to = "Index", values_to = "Value") %>%
  mutate(Index = forcats::fct_relevel(Index, "p (direction)", "p (0)", "p (ROPE)", "BF (0)", "BF (ROPE)")) %>%
  ggplot(aes(x=Evidence, y=Value, color=Index, group=1)) +
  geom_line(size=2) +
  scale_color_manual(values = c("p (direction)"="#9C27B0", "p (0)"="#f44336", "p (ROPE)"="#FFC107", "BF (0)"="#4CAF50", "BF (ROPE)"="#CDDC39"), guide=FALSE) +
  facet_wrap(~Index, nrow=5, scales = "free") +
  ylab("") +
  xlab("Evidence (Sample Size)") +
  see::theme_modern() +
  gganimate::transition_reveal(Evidence)

setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/Bayesian")

anim <- animate(p_significance)
anim_save("significance.gif", anim)

```

**p_posterior**

This gif represents the change in the posterior distribution as evidence (number of trials) increases. The posterior distribution first starts as the prior distribution which I set as a cauchy distribution centred as 0 and with a scale of 0.1. The cauchy distribution is often used for default priors due to it having fat tails. This means higher probability is assigned to relatively large effect sizes. Because large effect size are unlikely in reality, this means the null model hypothesis is favoured slightly more which provides conservative prior. 

As evidence increases, the posterior distribution takes shape. The median of the distribution moves away from the centre and towards the a coefficient effect of -0.2. The distribution also gets taller as the probability of the most credible values increases as more evidence is accumulated. 


**p_significance**

*p(direction)*

This represents the probaility of the direction of the effect and ranges from 50% i.e. the effect could be positive or negative to 100% i.e. the effect is clear completely positive or negative. As data is analysed via Bayes rule, I find that the probability of direction hits 100% at around 50 trials. 

*p(0)*

This represents the growth of the Bayesian equivalent to the frequentist p value i.e. the maximum a posteriori. It mirrors the other metrics by being driven down to 0.

*p(ROPE)*

This represents the percentage of the posterior distribution that is in a region of practical equivalance to the point null value. Just before 200 trials, it is driven down to 0%, thus 0% of the most credible values of the effect are practically equivalent to the null. 

*BF(0) and BF(ROPE)*

Here I make a slight alteration to the code. I take the inverse of the Bayes factor and the Bayes factor ROPE as specified here (https://easystats.github.io/report/articles/interpret_metrics.html#bayes-factor-bf). This means that the interpretation of these Bayes factors are now the amount of evidence in favour of the null model hypothesis, given the data. As data is collected, evidence for the null model gets driven down to zero. The alternative hypothesis is thus more likely given the data that is obtained.

## Saving figures

```{r}
p1 <- magick::image_read(animate(p_correlation, duration=nrow(magnitudedata)/4, fps=20))
p2 <- magick::image_read(animate(p_posterior, duration=nrow(magnitudedata)/4, fps=20))
p3 <- magick::image_read(animate(p_significance, duration=nrow(magnitudedata)/4, fps=20))

final <- magick::image_append(c(p1[1], p2[1], p3[1]))
for(i in 2:length(p2)){
  combined <- magick::image_append(c(p1[i], p2[i], p3[i]))
  final <- c(final, combined)
}

# Save final
gganimate::anim_save("evidence_accumulation.gif", final)

```